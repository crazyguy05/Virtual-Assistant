{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc435314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# requests.get(\"http://localhost:11434\").status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84ee67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68956bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ollama = OpenAI(base_url=\"http://localhost:11434/v1\",\n",
    "                api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273c66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d0a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant that can answer questions and help with tasks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72d8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20dd039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = input(\"you:\")\n",
    "# messages.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83e0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response=Ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "# assistant_reply = response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02ef3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "# print(f\"AI: {assistant_reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1597d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"you:\")\n",
    "    \n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"AI: Goodbye!\")\n",
    "#         break\n",
    "    \n",
    "#     messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "#     response=Ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "#     assistant_reply = response.choices[0].message.content\n",
    "#     messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "#     print(f\"AI: {assistant_reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f33ca7",
   "metadata": {},
   "source": [
    "Now factoring in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3f7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assistant_reply(messages):\n",
    "    response=Ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "046d09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(message, text):\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "def add_assistant_message(message, text):\n",
    "    messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e98cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"you:\")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"AI: Goodbye!\")\n",
    "#         break\n",
    "#     add_user_message(user_assistant_reply)\n",
    "#     print(f\"AI: {assistant_reply}\")input)\n",
    "#     assistant_reply = get_assistant_reply(messages)\n",
    "#     add_assistant_message("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b095e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_from_microphone():\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone(device_index=4) as source:\n",
    "        print(\"Calibrating mic...\")\n",
    "        r.adjust_for_ambient_noise(source, duration=1.5)\n",
    "\n",
    "        print(\"Speak now...\")\n",
    "        audio = r.listen(\n",
    "            source,\n",
    "            timeout=None,\n",
    "            phrase_time_limit=8\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(f\"You said: {text}\")\n",
    "        return text\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio.\")\n",
    "        return \"\"\n",
    "\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Recognition error: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: hello\n",
      "\n",
      "AI: Hello! How can I assist you today?\n",
      "----------------------------------------\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "Recognition error: recognition connection failed: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: my name is Gafoor\n",
      "\n",
      "AI: Hello Gafoor, it's nice to meet you. Is there anything on your mind that you'd like to talk about or ask for help with?\n",
      "----------------------------------------\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "Recognition error: recognition connection failed: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: do you know there is a popular song\n",
      "\n",
      "AI: You're referring to the popular song \"Askeka\" by the Norwegian-Nigerian duo Kygo and Selena Gomez, featuring Philanthropist and singer-songwriter Aloe Blacc. The song was released in 2018 and became a huge hit worldwide. Is there something specific you'd like to know about the song or its background?\n",
      "----------------------------------------\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: no\n",
      "\n",
      "AI: The song \"Askeka\" by Kygo, Selena Gomez, and Aloe Blue may not be widely known outside of certain circles, so it's possible that Gafoor is a fans of the song. Can you tell me more about why you're interested in this song? Is there something specific you'd like to know or discuss about it?\n",
      "----------------------------------------\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "Could not understand audio.\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: what is my name\n",
      "\n",
      "AI: Your name is Gafoor.\n",
      "----------------------------------------\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "Could not understand audio.\n",
      "Calibrating mic...\n",
      "Speak now...\n",
      "Recognition error: recognition connection failed: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "Calibrating mic...\n",
      "Speak now...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = listen_from_microphone()\n",
    "\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"AI: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    add_user_message(messages, user_input)\n",
    "\n",
    "    assistant_reply = get_assistant_reply(messages)\n",
    "\n",
    "    add_assistant_message(messages, assistant_reply)\n",
    "\n",
    "    print(\"\\nAI:\", assistant_reply)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8246a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import speech_recognition as sr\n",
    "\n",
    "# mics = sr.Microphone.list_microphone_names()\n",
    "# for i, name in enumerate(mics):\n",
    "#     print(f\"{i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3930a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pywin32 components loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# import pyttsx3\n",
    "# import pythoncom\n",
    "# import pywintypes\n",
    "\n",
    "# print(\"pywin32 components loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speak_text(text):\n",
    "#     engine = pyttsx3.init()\n",
    "#     engine.say(text)\n",
    "#     engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speak_text(\"Hello Yash, your voice assistant is working.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1bb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating mic...\n",
      "Speak now...\n",
      "You said: hello\n",
      "Calibrating mic...\n",
      "Speak now...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     user_input = \u001b[43mlisten_from_microphone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_input:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mlisten_from_microphone\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m     r.adjust_for_ambient_noise(source, duration=\u001b[32m1.5\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpeak now...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     16\u001b[39m     text = r.recognize_google(audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32my:\\AI Engineering Projects\\Voice assistant\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:461\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    459\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32my:\\AI Engineering Projects\\Voice assistant\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:531\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time - phrase_start_time > phrase_time_limit:\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    533\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32my:\\AI Engineering Projects\\Voice assistant\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:192\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32my:\\AI Engineering Projects\\Voice assistant\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# while True:\n",
    "#     user_input = listen_from_microphone()\n",
    "#     print(\"DEBUG: reached after microphone\")\n",
    "\n",
    "\n",
    "#     if not user_input:\n",
    "#         # continue\n",
    "\n",
    "#     if \"exit\" in user_input.lower():\n",
    "#         speak_text(\"Goodbye Yash\")\n",
    "#         break\n",
    "\n",
    "#     add_user_message(messages, user_input)\n",
    "\n",
    "#     assistant_reply = get_assistant_reply(messages)\n",
    "# print(\"AI TEXT:\", assistant_reply)\n",
    "# add_assistant_message(messages, assistant_reply)\n",
    "# speak_text(assistant_reply)\n",
    "\n",
    "# time.sleep(0.8)   # <-- IMPORTANT: give the mic time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
